{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "One of the challenges with this dataset was that all of its attributes, save for the test scores, were categorical. One of the advantages was that many of the categories were binary (lunch status/test completion/gender), and that was something we wanted to look into in more detail. As our initial plan involved decision trees and forests, we were hopeful that grouping by binary attributes would prove useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot_chart(table, s_att, s_ops, s_labels, chart_title):\n",
    "    '''\n",
    "        Create a dot/strip chart of frequency based on att\n",
    "    '''\n",
    "    title = \"Score Distribution by \" + chart_title\n",
    "    fname = chart_title.lower().replace(' ', '_') + '_plot.pdf'\n",
    "\n",
    "    m1 = [int(x[-3].strip('\"')) for x in table if x[s_att] == s_ops[0]]\n",
    "    m2 = [int(x[-3].strip('\"')) for x in table if x[s_att] == s_ops[1]]\n",
    "\n",
    "    r1 = [int(x[-2].strip('\"')) for x in table if x[s_att] == s_ops[0]]\n",
    "    r2 = [int(x[-2].strip('\"')) for x in table if x[s_att] == s_ops[1]]\n",
    "\n",
    "    w1 = [int(x[-1].strip('\"')) for x in table if x[s_att] == s_ops[0]]\n",
    "    w2 = [int(x[-1].strip('\"')) for x in table if x[s_att] == s_ops[1]]\n",
    "\n",
    "    gps = [m1, m2, r1, r2, w1, w2]\n",
    "    y_vals = [[y + 1 for i in range(len(group))] for y, group in enumerate(gps)]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Raw Exam Score out of 100\")\n",
    "    avxs = [np.mean(x) for x in gps]\n",
    "    avys = [y_vals[x][0] for x in range(len(avxs))]\n",
    "    colors = ['olive', 'purple', 'orange', 'crimson',  'slateblue', 'mediumturquoise']\n",
    "    for i, g in enumerate(gps):\n",
    "        plt.scatter(g, y_vals[i], marker='.', s=500, alpha=0.05, color=colors[i])\n",
    "\n",
    "    plt.scatter(avxs,avys, marker='x', s=250, alpha=1.0, c='black')\n",
    "    ytks = avys\n",
    "    ylbs = ['Math-' + s_labels[0], 'Math-' + s_labels[1],\n",
    "            'Reading-' + s_labels[0], 'Reading-' + s_labels[1],\n",
    "            'Writing-' + s_labels[0], 'Writing-' + s_labels[1],]\n",
    "    plt.yticks(ticks=ytks, labels=ylbs)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'strip_quotation_marks_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/OneDrive - Gonzaga University/C310/CPSC310-StudentsPerformance/exploratory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_quotation_marks_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# make_dot_chart(s, 0, ['female', 'male'], [\"Female\", \"Male\"], \"Gender\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# make_dot_chart(s, 3, ['standard', 'free/reduced'], [\"Standard\", \"Free/Reduced\"], \"Lunch Status\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'strip_quotation_marks_list'"
     ]
    }
   ],
   "source": [
    "f = 'StudentsPerformance.csv'\n",
    "students = utils.read_table(f)\n",
    "h = students[0]\n",
    "s = utils.strip_quotation_marks_list(students[1:])\n",
    "# make_dot_chart(s, 0, ['female', 'male'], [\"Female\", \"Male\"], \"Gender\")\n",
    "# make_dot_chart(s, 3, ['standard', 'free/reduced'], [\"Standard\", \"Free/Reduced\"], \"Lunch Status\")\n",
    "# make_dot_chart(s, 4, ['completed', 'none'], [\"Prep Course\", \"No Prep Course\"], \"Preparation Course Completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data was interesting to look at. Math seemed to be the subject that varied the most across all three groupings, while writing and reading seemed very similar to one another. After experimenting with results classifying as grades (A, B, C, D, F), we decided the simplest approach would be to try and predict whether or not a score was passing (>= 60) or failing. This was represented numerically as a 0 for failing and a 1 for passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "This was our new topic, and one of the more difficult things we attempted. What we ended up with was less a \"Neural Network\" and more a \"Best Neuron\" predictor. This was because we did not acheive any hidden layers between input and output, only a single neuron. This way, we were not required to do backpropagation in order to teach the system, we only had to update the weights of the single output neuron. \n",
    "\n",
    "Starting this endeavor, we had to convert all of our attributes to numbers. We converted lunch status to 1 (free/reduced) or 2 (standard), preparation course to 0 (no course) or 1 (completed), parents education to 1 (high school degree or some highschool), 2 (associate's degree or some college) or 3 (college or masters degree). "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
